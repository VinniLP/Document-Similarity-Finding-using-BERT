# Document-Similarity-Finding-using-BERT
Recently, there has been growing interest in the ability of Transformer based models to produce meaningful embeddings of text with several applications, such as text similarity. Despite significant progress in the field, the explanations for similarity predictions remain challenging, especially in unsupervised settings.
       </p> In this work, we present  an unsupervised technique  for  explaining  paragraph  similarities  inferred  by
pre-trained BERT models. 


## Methodology
- ### Approach 1
    - In this approach, we have just the sentences as inputs to the model , the model encodes it and find the similarity percentage.
- ### Approach 2
    - In this approach, we have first tokenized the sentences and then passed the tokens to the model. 
    - By doing so it helps in increasing the accuuracy of the model.

- ## Heat Map
    - For creating Heat Map,we have broken down paragraph into sentences,to look sentences-to-sentences semantic similarity. 
    
    
- ### Approach 1
    - In this approach, we have just the sentences as inputs to the model , the model encodes it and find the similarity percentage.
- ### Approach 2
    - In this approach, we have first tokenized the sentences and then passed the tokens to the model. 
    - By doing so it helps in increasing the accuuracy of the model.

- ## Heat Map
    - For creating Heat Map,we have broken down paragraph into sentences,to look sentences-to-sentences semantic similarity. 
    
    